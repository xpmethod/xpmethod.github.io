---
layout: project
title: Hate Speech and Online Activism 
tags:
- Phillip R. Polefrone
category: public-discourse
type: public policy
prompt: #GamerGate and movements like it have revitalized a longstanding debate on the limits of the "free-speech" argument when discussing hate speech. Combining theoretical, historical, and legal research with a quantitative semantic analysis of tweets using the #GamerGate hashtag will put recent events in context. It will also begin to answer the question: How does hate speech operate online? Where do tweets like those of #GamerGate fit in the current legal definitions of hate speech? And, crucially, how can an understanding of this evolving language be used to protect online activists?
snippet: 150
published: true
---

Since the beginning of #GamerGate in 2014, threats to online feminist activists and their allies have been routine, as have bomb threats and public shaming on Twitter and beyond. Legislators are scrambling to respond: in March 2015, to take a recent example, Representative Katherine Clark called to strengthen the parts of the Violence Against Women Act that protect victims of online stalking and harassment. Measures such as these are obviously necessary, but several fundamental questions remain unasked about the language under consideration: How does online hate speech differ from previous forms of hate speech? Will the legal structures that define threatening and criminally harassing language as civil rights violations be able to keep up with the linguistic petri dish of social media? How closely do these definitions describe the type of harassment that is actually occurring, and are there any ways in which it is deficient? 

This project will attempt to answer these questions by analyzing the language of a large corpus of tweets that use the #GamerGate hashtag. The vast majority of the existing work on #GamerGate has been network analysis, and while such work is unquestionably useful for any social media topic, its exclusion of semantic content limits its applications. Most notably for my purposes, network analysis does not allow us to ask whether and how these tweets operate as hate speech. 

To address this question will require several distinct modes of comparison. To establish a reliable working definition of hate speech will require close-reading of existing legislation and an historical overview of criminal harassment in hate crime prosecution. When this foundation has been established, corpus analysis of current and historical tweet content will be able to begin. Finally, quantitative comparison of this corpus analysis with recognized records of hate speech and criminal harassment will put these utterances in a clear context. Simply put, the goal of the project will be to provide quantitative support to existing scholarship on online hate crimes, both to make it more useful to policy makers and to demonstrate the extent and nature of an increasingly pernicious problem. 

#Policy Application 

This research could have a considerable impact on policy decisions because of the amount of available data and the renewed focus on protecting online civil liberties.The acts in question, by their nature, are easily traceable, and samples from the past several years have been retained as datasets for prior research. (New data can be easily gathered using Twitter's API.) The results of this research can readily be put to use in recent initiatives to buttress legislation like President Obama's Violence Against Women Reauthorization Act of 2013 (VAWA), which specifically strengthens the government's ability to protect victims of online harassment, and The Matthew Shepard and James Byrd, Jr. Hate Crimes Act of 2009. This legislation is likely to be revisited again in the wake of #Gamergate due to the efforts of legislators like Representative Katherine Clark and others. With the aid of this research, a more powerful case could be made and more precise protections could be offered to the victims of online attacks.
